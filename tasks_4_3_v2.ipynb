{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuhrat9902/my_first_repository/blob/main/tasks_4_3_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4DXLeeZKq4A"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import unittest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import io\n",
        "import contextlib # For redirecting stdout\n",
        "from urllib.error import URLError\n",
        "import warnings\n",
        "import sys\n",
        "import os\n",
        "# from pathlib import Path # Not used in current run_tests, but maybe intended\n",
        "# from typing import List, Any, Optional, Tuple, Dict # Not used, but good practice\n",
        "\n",
        "_DATASET_CACHE = {}\n",
        "def load_cached_dataset(name):\n",
        "    \"\"\"\n",
        "    Loads a seaborn dataset using caching.\n",
        "    Returns the DataFrame or raises an error if loading fails.\n",
        "    \"\"\"\n",
        "    if name not in _DATASET_CACHE:\n",
        "        print(f\"\\nAttempting to load dataset '{name}'...\")\n",
        "        try:\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.simplefilter(\"ignore\")\n",
        "                # Specify cache location and attempt loading\n",
        "                df = sns.load_dataset(name, cache=True, data_home='./seaborn-data')\n",
        "\n",
        "            if df is None:\n",
        "                # This case might happen if the dataset name is invalid but doesn't raise an Exception directly\n",
        "                raise ValueError(f\"sns.load_dataset('{name}') returned None. Dataset might not exist or is empty.\")\n",
        "\n",
        "            _DATASET_CACHE[name] = df\n",
        "            print(f\"Dataset '{name}' loaded successfully ({df.shape[0]} rows, {df.shape[1]} cols).\")\n",
        "\n",
        "        except (ValueError, URLError, TimeoutError, ConnectionError, FileNotFoundError, ImportError, Exception) as e:\n",
        "            # Log the error clearly and re-raise it to signal failure to the calling test\n",
        "            print(f\"------------------------------------------------------\")\n",
        "            print(f\"ERROR: Data loading failed for '{name}': {type(e).__name__} - {e}\")\n",
        "            print(f\"Tests relying on '{name}' will likely fail or be skipped.\")\n",
        "            print(f\"------------------------------------------------------\")\n",
        "            # Re-raise the exception so the test framework knows something went wrong during setup/function execution\n",
        "            # Or alternatively, return None and let tests handle it via skipping (less explicit failure)\n",
        "            # Returning None for now to keep skipTest logic functional\n",
        "            _DATASET_CACHE[name] = None # Cache the failure signal\n",
        "            # raise e # Option 1: Make tests fail immediately\n",
        "\n",
        "    # Return a copy if loaded successfully, otherwise return None (or raise error if preferred)\n",
        "    cached_data = _DATASET_CACHE.get(name)\n",
        "    return cached_data.copy() if cached_data is not None else None\n",
        "\n",
        "# --- Provided Test Runner Function ---\n",
        "def run_tests(test_class):\n",
        "    \"\"\"Runs tests from a specific unittest.TestCase subclass.\"\"\"\n",
        "    print(f\"\\n--- Running tests from {test_class.__name__} ---\")\n",
        "    # Use defaultTestLoader for compatibility\n",
        "    suite = unittest.defaultTestLoader.loadTestsFromTestCase(test_class)\n",
        "    # Ensure output goes to stdout even in environments that might redirect it\n",
        "    runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout, buffer=False) # buffer=False might help in some notebook setups\n",
        "\n",
        "    result = runner.run(suite)\n",
        "    print(f\"--- Finished tests for {test_class.__name__} ---\")\n",
        "\n",
        "    print(\"-\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, here are the descriptions for the provided functions (Exercises 1-6), following the style of your examples:\n",
        "\n",
        "**Head/Tail Data Inspection / Инспекция Начальных/Конечных Данных**\n",
        "\n",
        "Score: 5\n",
        "\n",
        "EN: Loads the 'tips' dataset using a helper function, extracts the first 3 rows (head) and the last 3 rows (tail), and returns them as a tuple of two DataFrames.\n",
        "\n",
        "RU: Загружает набор данных 'tips' с помощью вспомогательной функции, извлекает первые 3 строки (head) и последние 3 строки (tail) и возвращает их в виде кортежа из двух DataFrame.\n",
        "\n",
        "**DataFrame Shape and Data Types / Форма и Типы Данных DataFrame**\n",
        "\n",
        "Score: 5\n",
        "\n",
        "EN: Loads the 'titanic' dataset, retrieves its dimensions (shape) and the data types of each column (dtypes), and returns these as a tuple.\n",
        "\n",
        "RU: Загружает набор данных 'titanic', получает его размерность (shape) и типы данных каждого столбца (dtypes) и возвращает их в виде кортежа.\n",
        "\n",
        "**Titanic Data Cleaning / Очистка Данных Титаника**\n",
        "\n",
        "Score: 20\n",
        "\n",
        "EN: Loads the 'titanic' dataset and applies a series of cleaning operations: converts 'age' to numeric (handling errors), fills missing 'age' with the mean, fills missing 'embarked' and 'embark\\_town' with their respective modes, and drops rows with missing 'deck' values. Returns the cleaned DataFrame.\n",
        "\n",
        "RU: Загружает набор данных 'titanic' и применяет серию операций очистки: преобразует 'age' в числовой формат (обрабатывая ошибки), заполняет пропущенные значения 'age' средним, заполняет пропущенные значения 'embarked' и 'embark\\_town' их соответствующими модами и удаляет строки с пропущенными значениями 'deck'. Возвращает очищенный DataFrame.\n",
        "\n",
        "**Text Processing and Filtering / Обработка Текста и Фильтрация**\n",
        "\n",
        "Score: 20\n",
        "\n",
        "EN: Loads the 'titanic' dataset, creates a 'category' column based on the 'who' column, converts 'category' to uppercase, and then filters the DataFrame twice: first for rows where 'category' is 'WOMAN', and second for rows where 'embarked' is 'S'. Returns the resulting filtered DataFrame.\n",
        "\n",
        "RU: Загружает набор данных 'titanic', создает столбец 'category' на основе столбца 'who', преобразует 'category' в верхний регистр, а затем дважды фильтрует DataFrame: сначала по строкам, где 'category' равно 'WOMAN', а затем по строкам, где 'embarked' равно 'S'. Возвращает итоговый отфильтрованный DataFrame.\n",
        "\n",
        "**Grouping and Aggregation / Группировка и Агрегация**\n",
        "\n",
        "Score: 20\n",
        "\n",
        "EN: Loads the 'tips' dataset, groups the data by 'day' and 'smoker', and then calculates aggregate statistics for each group: the mean of 'total\\_bill' (as 'avg\\_bill'), the maximum 'tip' (as 'max\\_tip'), and the count of entries (as 'count'). Returns the resulting aggregated DataFrame with a MultiIndex.\n",
        "\n",
        "RU: Загружает набор данных 'tips', группирует данные по 'day' и 'smoker', а затем вычисляет агрегированную статистику для каждой группы: среднее значение 'total\\_bill' (как 'avg\\_bill'), максимальное значение 'tip' (как 'max\\_tip') и количество записей (как 'count'). Возвращает итоговый агрегированный DataFrame с MultiIndex.\n",
        "\n",
        "**Car Name Extraction and Cleaning / Извлечение и Очистка Названий Автомобилей**\n",
        "\n",
        "Score: 30\n",
        "\n",
        "EN: Loads the 'mpg' dataset, extracts the first word from the 'name' column into 'initial\\_brand'. It then cleans common typos in 'initial\\_brand' (e.g., 'chevy' to 'chevrolet') to create a final 'brand' column using mapping. Finally, it creates a 'cleaned\\_name' column by removing the first word from the original 'name' and joining the remaining parts using string accessor methods. Returns the DataFrame with these new columns.\n",
        "\n",
        "RU: Загружает набор данных 'mpg', извлекает первое слово из столбца 'name' в 'initial\\_brand'. Затем очищает распространенные опечатки в 'initial\\_brand' (например, 'chevy' в 'chevrolet') для создания итогового столбца 'brand', используя сопоставление (mapping). Наконец, создает столбец 'cleaned\\_name', удаляя первое слово из исходного 'name' и соединяя оставшиеся части, используя методы строкового аксесора. Возвращает DataFrame с этими новыми столбцами."
      ],
      "metadata": {
        "id": "DBZfjGxlrNVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Head/Tail Data Inspection / Инспекция Начальных/Конечных Данных"
      ],
      "metadata": {
        "id": "HI0kfUcUrd_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exercise_1_load_and_inspect_head_tail():\n",
        "    \"\"\"\n",
        "    Loads the 'tips' dataset, returns head(3)/tail(3). Returns (head_df, tail_df) or (None, None).\n",
        "\n",
        "    Загружает набор данных 'tips', возвращает head(3)/tail(3). Возвращает (head_df, tail_df) или (None, None).\n",
        "\n",
        "    Source/Источник: https://rdrr.io/cran/reshape2/man/tips.html\n",
        "    \"\"\"\n",
        "    dataset_name = 'tips'\n",
        "    print(f\"\\n--- Running Exercise 1 body: Load '{dataset_name}' ---\")\n",
        "    try:\n",
        "        df = load_cached_dataset(dataset_name)\n",
        "        if df is None or df.empty:\n",
        "             print(f\"INFO Ex1: Cannot run exercise body: DataFrame '{dataset_name}' is empty or None.\")\n",
        "             # Return tuple of Nones consistent with success/failure paths\n",
        "             return None, None\n",
        "\n",
        "        df_processed = df.copy()\n",
        "\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in exercise_1 body: {type(e).__name__} - {e}\")\n",
        "        return None, None\n",
        "\n",
        "list(map(lambda x: display(x), exercise_1_load_and_inspect_head_tail()));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "_HbsrDd6z61K",
        "outputId": "33d5490f-1676-4946-9563-ad9da5976dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 1 body: Load 'tips' ---\n",
            "\n",
            "Attempting to load dataset 'tips'...\n",
            "Dataset 'tips' loaded successfully (244 rows, 7 cols).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestExercise1(unittest.TestCase):\n",
        "    def test_ex1_logic(self):\n",
        "        \"\"\"Test Ex1: Checks return types, lengths, and specific values for head/tail.\"\"\"\n",
        "        print(\"\\nRunning test_ex1_logic...\") # Test-specific print\n",
        "        # Suppress prints from the exercise function itself during the test run\n",
        "        with contextlib.redirect_stdout(io.StringIO()) as captured_output:\n",
        "            head, tail = exercise_1_load_and_inspect_head_tail() # Call without argument\n",
        "\n",
        "        # Optional: Print captured output for debugging if needed\n",
        "        # print(\"Captured output from exercise_1:\\n\", captured_output.getvalue())\n",
        "\n",
        "        if head is None and tail is None:\n",
        "            # Check if the reason was explicit return due to load failure vs. exception\n",
        "            func_output = captured_output.getvalue()\n",
        "            if \"Cannot run exercise body\" in func_output or \"ERROR loading dataset\" in func_output:\n",
        "                 self.skipTest(\"Ex1 Skipped: Function returned (None, None), data load issue detected.\")\n",
        "            else:\n",
        "                 # If (None, None) returned due to unexpected exception within try block\n",
        "                 self.fail(\"Ex1 Failed: Function returned (None, None) unexpectedly. Check logs.\")\n",
        "\n",
        "\n",
        "        # --- Assertions remain the same as they test the logic based on 'tips' ---\n",
        "        # Check types\n",
        "        self.assertIsInstance(head, pd.DataFrame, \"Ex1 Head is not a DataFrame\")\n",
        "        self.assertIsInstance(tail, pd.DataFrame, \"Ex1 Tail is not a DataFrame\")\n",
        "\n",
        "        # Check non-emptiness\n",
        "        self.assertFalse(head.empty, \"Ex1 Head DF is empty\")\n",
        "        self.assertFalse(tail.empty, \"Ex1 Tail DF is empty\")\n",
        "\n",
        "        # Check lengths\n",
        "        self.assertEqual(len(head), 3, \"Ex1 Head Length Check Failed\")\n",
        "        self.assertLessEqual(len(tail), 3, \"Ex1 Tail Length Check Failed (> 3)\") # Tail might be < 3 if dataset is tiny\n",
        "        self.assertGreaterEqual(len(tail), 1, \"Ex1 Tail Length Check Failed (<= 0)\") # Should have at least 1 row if not empty\n",
        "\n",
        "        # Check specific values (assuming 'tips' dataset loaded correctly)\n",
        "        # Use .iloc for position-based access, less prone to index changes\n",
        "        self.assertEqual(head.iloc[0]['sex'], 'Female', \"Ex1 Head[0] sex mismatch\")\n",
        "        self.assertEqual(head.iloc[2]['day'], 'Sun', \"Ex1 Head[2] day mismatch\")\n",
        "        self.assertEqual(tail.iloc[-1]['total_bill'], 18.78, \"Ex1 Tail[-1] total_bill mismatch\")\n",
        "        self.assertEqual(tail.iloc[-2]['smoker'], 'No', \"Ex1 Tail[-2] smoker mismatch\")\n",
        "        print(\"Test test_ex1_logic PASSED.\")\n",
        "\n",
        "# --- Run Function and Tests ---\n",
        "list(map(lambda x: display(x), exercise_1_load_and_inspect_head_tail()));\n",
        "run_tests(TestExercise1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "6LyrBZc4K0Q0",
        "outputId": "2f84075d-0cce-48d2-c284-7179a8ec2a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 1 body: Load 'tips' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running tests from TestExercise1 ---\n",
            "test_ex1_logic (__main__.TestExercise1.test_ex1_logic)\n",
            "Test Ex1: Checks return types, lengths, and specific values for head/tail. ... \n",
            "Running test_ex1_logic...\n",
            "FAIL\n",
            "\n",
            "======================================================================\n",
            "FAIL: test_ex1_logic (__main__.TestExercise1.test_ex1_logic)\n",
            "Test Ex1: Checks return types, lengths, and specific values for head/tail.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-16-51ad0c98a8ac>\", line 19, in test_ex1_logic\n",
            "    self.fail(\"Ex1 Failed: Function returned (None, None) unexpectedly. Check logs.\")\n",
            "AssertionError: Ex1 Failed: Function returned (None, None) unexpectedly. Check logs.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.003s\n",
            "\n",
            "FAILED (failures=1)\n",
            "--- Finished tests for TestExercise1 ---\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataFrame Shape and Data Types / Форма и Типы Данных DataFrame\n"
      ],
      "metadata": {
        "id": "-akITB9yriyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exercise_2_check_shape_info_dtypes():\n",
        "    \"\"\"\n",
        "    Loads the 'titanic' dataset, returns shape and dtypes. Returns (shape, dtypes) or (None, None).\n",
        "\n",
        "    Загружает набор данных 'titanic', возвращает shape и dtypes. Возвращает (shape, dtypes) или (None, None).\n",
        "\n",
        "    Source/Источник: https://www.kaggle.com/c/titanic/data\n",
        "    \"\"\"\n",
        "    dataset_name = 'titanic' # Hardcoded dataset name\n",
        "    print(f\"\\n--- Running Exercise 2 body: Load '{dataset_name}' ---\")\n",
        "    try:\n",
        "        df = load_cached_dataset(dataset_name)\n",
        "        if df is None or df.empty:\n",
        "             print(f\"INFO Ex2: Cannot run exercise body: DataFrame '{dataset_name}' is empty or None.\")\n",
        "             # Return tuple of Nones consistent with success/failure paths\n",
        "             return None, None\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in exercise_2 body: {type(e).__name__} - {e}\")\n",
        "        return None, None\n",
        "\n",
        "list(map(lambda x: display(x), exercise_2_check_shape_info_dtypes()));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "NevE4hfw0Egs",
        "outputId": "2ba668c3-3f2d-4f11-f975-c48a0e533579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 2 body: Load 'titanic' ---\n",
            "\n",
            "Attempting to load dataset 'titanic'...\n",
            "Dataset 'titanic' loaded successfully (891 rows, 15 cols).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Tests for Exercise 2 ---\n",
        "class TestExercise2(unittest.TestCase):\n",
        "     def test_ex2_logic(self):\n",
        "        \"\"\"Test Ex2: Checks return types, shape values, and specific dtypes for 'titanic'.\"\"\"\n",
        "        print(\"\\nRunning test_ex2_logic...\")\n",
        "        # Suppress prints from the exercise function itself during the test run\n",
        "        with contextlib.redirect_stdout(io.StringIO()) as captured_output:\n",
        "             shape, dtypes = exercise_2_check_shape_info_dtypes() # Call without argument\n",
        "\n",
        "        if shape is None and dtypes is None:\n",
        "            func_output = captured_output.getvalue()\n",
        "            if \"Cannot run exercise body\" in func_output or \"ERROR loading dataset\" in func_output:\n",
        "                 self.skipTest(\"Ex2 Skipped: Function returned (None, None), data load issue detected.\")\n",
        "            else:\n",
        "                 self.fail(\"Ex2 Failed: Function returned (None, None) unexpectedly. Check logs.\")\n",
        "\n",
        "        # --- Assertions ---\n",
        "        self.assertIsInstance(shape, tuple, \"Ex2 Shape is not a tuple\")\n",
        "        self.assertEqual(len(shape), 2, \"Ex2 Shape tuple length invalid\")\n",
        "        self.assertIsInstance(dtypes, pd.Series, \"Ex2 Dtypes is not a Series\")\n",
        "        self.assertFalse(dtypes.empty, \"Ex2 Dtypes series is empty\")\n",
        "\n",
        "        # Specific checks for the 'titanic' dataset loaded via seaborn\n",
        "        # These might fail if a different version/source of 'titanic' is loaded\n",
        "        self.assertEqual(shape[0], 891, f\"Ex2 Expected 891 rows, got {shape[0]}\")\n",
        "        self.assertEqual(shape[1], 15, f\"Ex2 Expected 15 columns, got {shape[1]}\")\n",
        "\n",
        "        # Check specific dtypes by index (less robust) or name (more robust)\n",
        "        # Assuming standard seaborn titanic dataset column order/names\n",
        "        # Index 0: 'survived' (int64)\n",
        "        # Index 1: 'pclass' (int64)\n",
        "        # Index 2: 'sex' (object/string)\n",
        "\n",
        "        # Using index (potentially fragile if columns change)\n",
        "        # self.assertEqual(dtypes.iloc[0].name, 'int64', f\"Ex2 dtype[0] expected int64, got {dtypes.iloc[0]}\")\n",
        "        # self.assertEqual(dtypes.iloc[2].name, 'object', f\"Ex2 dtype[2] expected object, got {dtypes.iloc[2]}\")\n",
        "\n",
        "        # Using column names (more robust)\n",
        "        self.assertTrue('survived' in dtypes.index, \"Ex2 'survived' column missing\")\n",
        "        self.assertEqual(dtypes['survived'].name, 'int64', f\"Ex2 dtype['survived'] expected int64, got {dtypes['survived']}\")\n",
        "\n",
        "        self.assertTrue('sex' in dtypes.index, \"Ex2 'sex' column missing\")\n",
        "        self.assertEqual(dtypes['sex'].name, 'object', f\"Ex2 dtype['sex'] expected object, got {dtypes['sex']}\")\n",
        "\n",
        "        # Check for a float type (e.g., 'age' or 'fare')\n",
        "        self.assertTrue('fare' in dtypes.index, \"Ex2 'fare' column missing\")\n",
        "        self.assertEqual(dtypes['fare'].name, 'float64', f\"Ex2 dtype['fare'] expected float64, got {dtypes['fare']}\")\n",
        "\n",
        "        print(\"Test test_ex2_logic PASSED.\")\n",
        "\n",
        "\n",
        "# --- Run Function and Tests ---\n",
        "list(map(lambda x: display(x), exercise_2_check_shape_info_dtypes()));\n",
        "run_tests(TestExercise2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "qR4ufIx3kyog",
        "outputId": "4ae9f2a9-3a77-4aea-fb8e-e3e151249297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 2 body: Load 'titanic' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running tests from TestExercise2 ---\n",
            "test_ex2_logic (__main__.TestExercise2.test_ex2_logic)\n",
            "Test Ex2: Checks return types, shape values, and specific dtypes for 'titanic'. ... \n",
            "Running test_ex2_logic...\n",
            "FAIL\n",
            "\n",
            "======================================================================\n",
            "FAIL: test_ex2_logic (__main__.TestExercise2.test_ex2_logic)\n",
            "Test Ex2: Checks return types, shape values, and specific dtypes for 'titanic'.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-18-59b7210c4d10>\", line 15, in test_ex2_logic\n",
            "    self.fail(\"Ex2 Failed: Function returned (None, None) unexpectedly. Check logs.\")\n",
            "AssertionError: Ex2 Failed: Function returned (None, None) unexpectedly. Check logs.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.003s\n",
            "\n",
            "FAILED (failures=1)\n",
            "--- Finished tests for TestExercise2 ---\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Titanic Data Cleaning / Очистка Данных Титаника\n",
        "\n"
      ],
      "metadata": {
        "id": "a_FNCFyXrnud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Exercise 3: Data Cleaning - Missing Values and Type Conversion (Corrected) ---\n",
        "def exercise_3_clean_titanic():\n",
        "    \"\"\"\n",
        "    Loads the 'titanic' dataset and performs cleaning steps:\n",
        "    1. Convert 'age' column to numeric, coercing errors to NaN.\n",
        "    2. Fill missing 'age' values with the mean age (calculated *after* coercion).\n",
        "    3. Fill missing 'embarked' values with the mode* of the 'embarked' column.\n",
        "    4. Fill missing 'embark_town' values with the mode* of the 'embark_town'.\n",
        "    5. Drop rows where 'deck' has a missing value (NaN).\n",
        "    Returns: The cleaned DataFrame or None.\n",
        "\n",
        "    Загружает набор данных 'titanic' и выполняет шаги очистки:\n",
        "    1. Преобразует столбец 'age' в числовой тип, приводя ошибки к NaN.\n",
        "    2. Заполняет пропущенные значения 'age' средним возрастом (рассчитанным *после* приведения типов).\n",
        "    3. Заполняет пропущенные значения 'embarked' модой* столбца 'embarked'.\n",
        "    4. Заполняет пропущенные значения 'embark_town' модой* столбца 'embark_town'.\n",
        "    5. Удаляет строки, в которых столбец 'deck' имеет пропущенное значение (NaN).\n",
        "    Возвращает: Очищенный DataFrame или None.\n",
        "\n",
        "    *Mode is tricky, the default function returns a tuple, please read on it here\n",
        "    *Мода - хитрая штука, функция по умолчанию возвращает кортеж, пожалуйста, прочтите об этом здесь:\n",
        "    https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html\n",
        "\n",
        "    Source/Источник: https://www.kaggle.com/c/titanic/data\n",
        "    \"\"\"\n",
        "    dataset_name = 'titanic' # Hardcoded dataset name\n",
        "    print(f\"\\n--- Running Exercise 3 body: Load and clean '{dataset_name}' ---\")\n",
        "    try:\n",
        "        df = load_cached_dataset(dataset_name)\n",
        "        if df is None or df.empty:\n",
        "             print(f\"INFO Ex3: Cannot run exercise body: DataFrame '{dataset_name}' is empty or None.\")\n",
        "             return None\n",
        "\n",
        "        df_cleaned = df.copy()\n",
        "\n",
        "        return None\n",
        "\n",
        "    except KeyError as ke:\n",
        "        print(f\"ERROR in exercise_3 body: KeyError - Likely a required column is missing: {ke}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in exercise_3 body: {type(e).__name__} - {e}\")\n",
        "        return None\n",
        "\n",
        "display(exercise_3_clean_titanic())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "H3LYhTW30LTB",
        "outputId": "77158650-f3c3-42dc-d476-23ab3d19c41b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 3 body: Load and clean 'titanic' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestExercise3(unittest.TestCase):\n",
        "    original_df = None\n",
        "    cleaned_df_final = None # Stores result of the *complete* exercise function\n",
        "\n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        \"\"\"Load original data and run the full cleaning process once.\"\"\"\n",
        "        print(\"\\nSetting up TestExercise3: Loading original data...\")\n",
        "        cls.original_df = load_cached_dataset('titanic')\n",
        "        if cls.original_df is None:\n",
        "            print(\"Setup FATAL: Failed to load original titanic data for TestExercise3.\")\n",
        "            # Individual tests will skip if original_df is None\n",
        "\n",
        "        print(\"\\nSetting up TestExercise3: Running full cleaning function...\")\n",
        "        # Run the complete function once\n",
        "        with contextlib.redirect_stdout(io.StringIO()): # Suppress function prints\n",
        "            cls.cleaned_df_final = exercise_3_clean_titanic()\n",
        "        if cls.cleaned_df_final is None:\n",
        "            print(\"Setup WARNING: Full cleaning function returned None.\")\n",
        "            # Tests requiring cleaned_df_final will skip\n",
        "\n",
        "    # --- Tests verifying consequences of individual steps ---\n",
        "\n",
        "    def test_consequences_step1_age_numeric(self):\n",
        "        \"\"\"Test Ex3 Step 1 Consequences: Check final 'age' dtype.\"\"\"\n",
        "        print(\"\\nRunning test_consequences_step1_age_numeric...\")\n",
        "        if self.cleaned_df_final is None:\n",
        "            self.skipTest(\"Ex3 Skipped (Step 1 - Age Numeric): Final cleaned data not available.\")\n",
        "        if 'age' not in self.cleaned_df_final.columns:\n",
        "             self.fail(\"Test Prerequisite Failed: 'age' column missing in final DataFrame.\")\n",
        "\n",
        "        # Assert: Check the final dtype of the 'age' column\n",
        "        self.assertTrue(pd.api.types.is_numeric_dtype(self.cleaned_df_final['age'].dtype),\n",
        "                        \"Step 1 Consequences Assert Failed: Final 'age' dtype is not numeric.\")\n",
        "        print(\"Test test_consequences_step1_age_numeric PASSED.\")\n",
        "\n",
        "\n",
        "    def test_consequences_step2_age_filled(self):\n",
        "        \"\"\"Test Ex3 Step 2 Consequences: Check final 'age' column has no NaNs.\"\"\"\n",
        "        print(\"\\nRunning test_consequences_step2_age_filled...\")\n",
        "        if self.cleaned_df_final is None:\n",
        "            self.skipTest(\"Ex3 Skipped (Step 2 - Age Filled): Final cleaned data not available.\")\n",
        "        if 'age' not in self.cleaned_df_final.columns:\n",
        "             self.fail(\"Test Prerequisite Failed: 'age' column missing in final DataFrame.\")\n",
        "\n",
        "        # Assert: Check for NaNs in the final 'age' column\n",
        "        final_age_nan_count = self.cleaned_df_final['age'].isnull().sum()\n",
        "        self.assertEqual(final_age_nan_count, 0,\n",
        "                         f\"Step 2 Consequences Assert Failed: Final 'age' column still has {final_age_nan_count} NaNs after fillna step should have run.\")\n",
        "\n",
        "        # Optional Assert: Check if a row known to have NaN age originally AND survived dropna\n",
        "        # now has a value close to the original mean age.\n",
        "        if self.original_df is not None:\n",
        "             idx_check = 5 # Passenger originally had NaN age\n",
        "             # Calculate mean age from original df *after* potential coercion\n",
        "             original_age_numeric = pd.to_numeric(self.original_df['age'], errors='coerce')\n",
        "             expected_mean = original_age_numeric.mean()\n",
        "\n",
        "             # Check if this row survived the dropna(subset=['deck']) step\n",
        "             if idx_check in self.cleaned_df_final.index:\n",
        "                 # Check if the original value was actually NaN\n",
        "                 if pd.isna(self.original_df.loc[idx_check, 'age']):\n",
        "                     self.assertAlmostEqual(self.cleaned_df_final.loc[idx_check, 'age'], expected_mean, places=4,\n",
        "                                            msg=f\"Step 2 Consequences Assert Failed: Passenger {idx_check} (orig NaN age) doesn't have approx mean age in final data.\")\n",
        "                 else:\n",
        "                     print(f\"INFO Test Step 2: Original age at index {idx_check} was not NaN.\")\n",
        "             else:\n",
        "                  print(f\"INFO Test Step 2: Passenger {idx_check} (orig NaN age) did not survive final dropna, cannot check filled value.\")\n",
        "\n",
        "        print(\"Test test_consequences_step2_age_filled PASSED.\")\n",
        "\n",
        "\n",
        "    def test_consequences_step3_embarked_filled(self):\n",
        "        \"\"\"Test Ex3 Step 3 Consequences: Check final 'embarked' column has no NaNs.\"\"\"\n",
        "        print(\"\\nRunning test_consequences_step3_embarked_filled...\")\n",
        "        if self.cleaned_df_final is None:\n",
        "            self.skipTest(\"Ex3 Skipped (Step 3 - Embarked Filled): Final cleaned data not available.\")\n",
        "        if 'embarked' not in self.cleaned_df_final.columns:\n",
        "             self.fail(\"Test Prerequisite Failed: 'embarked' column missing in final DataFrame.\")\n",
        "\n",
        "        # Assert: Check for NaNs in the final 'embarked' column\n",
        "        final_embarked_nan_count = self.cleaned_df_final['embarked'].isnull().sum()\n",
        "        self.assertEqual(final_embarked_nan_count, 0,\n",
        "                         f\"Step 3 Consequences Assert Failed: Final 'embarked' column still has {final_embarked_nan_count} NaNs.\")\n",
        "\n",
        "        # Optional Assert: Check specific rows known to have NaN embarked originally\n",
        "        # ONLY if they survived the final dropna step.\n",
        "        if self.original_df is not None:\n",
        "            original_mode = self.original_df['embarked'].mode()[0] # Get expected fill value\n",
        "            for idx in [61, 829]: # Indices known to have NaN embarked originally\n",
        "                if idx in self.cleaned_df_final.index: # Check if row survived\n",
        "                    if pd.isna(self.original_df.loc[idx, 'embarked']): # Check if it was originally NaN\n",
        "                        self.assertEqual(self.cleaned_df_final.loc[idx, 'embarked'], original_mode,\n",
        "                                         f\"Step 3 Consequences Assert Failed: Passenger {idx} (orig NaN embarked) doesn't have mode '{original_mode}' in final data.\")\n",
        "                    else:\n",
        "                        print(f\"INFO Test Step 3: Original embarked at index {idx} was not NaN.\")\n",
        "                else:\n",
        "                    print(f\"INFO Test Step 3: Passenger {idx} (orig NaN embarked) did not survive final dropna.\")\n",
        "\n",
        "        print(\"Test test_consequences_step3_embarked_filled PASSED.\")\n",
        "\n",
        "\n",
        "    def test_consequences_step4_embark_town_filled(self):\n",
        "        \"\"\"Test Ex3 Step 4 Consequences: Check final 'embark_town' has no NaNs.\"\"\"\n",
        "        print(\"\\nRunning test_consequences_step4_embark_town_filled...\")\n",
        "        if self.cleaned_df_final is None:\n",
        "            self.skipTest(\"Ex3 Skipped (Step 4 - Embark Town Filled): Final cleaned data not available.\")\n",
        "        if 'embark_town' not in self.cleaned_df_final.columns:\n",
        "             self.skipTest(\"Ex3 Skipped (Step 4): 'embark_town' column not in final data.\")\n",
        "\n",
        "        # Assert: Check for NaNs in the final 'embark_town' column\n",
        "        final_town_nan_count = self.cleaned_df_final['embark_town'].isnull().sum()\n",
        "        self.assertEqual(final_town_nan_count, 0,\n",
        "                         f\"Step 4 Consequences Assert Failed: Final 'embark_town' column still has {final_town_nan_count} NaNs.\")\n",
        "\n",
        "        # Optional Assert: Check specific rows known to have NaN embark_town originally\n",
        "        if self.original_df is not None and 'embark_town' in self.original_df.columns:\n",
        "             original_mode = self.original_df['embark_town'].mode()[0] # Get expected fill value\n",
        "             for idx in [61, 829]: # Indices known to have NaN embark_town originally\n",
        "                 if idx in self.cleaned_df_final.index: # Check if row survived\n",
        "                     if pd.isna(self.original_df.loc[idx, 'embark_town']): # Check if it was originally NaN\n",
        "                         self.assertEqual(self.cleaned_df_final.loc[idx, 'embark_town'], original_mode,\n",
        "                                          f\"Step 4 Consequences Assert Failed: Passenger {idx} (orig NaN town) doesn't have mode '{original_mode}' in final data.\")\n",
        "                     else:\n",
        "                          print(f\"INFO Test Step 4: Original embark_town at index {idx} was not NaN.\")\n",
        "                 else:\n",
        "                     print(f\"INFO Test Step 4: Passenger {idx} (orig NaN town) did not survive final dropna.\")\n",
        "\n",
        "        print(\"Test test_consequences_step4_embark_town_filled PASSED.\")\n",
        "\n",
        "\n",
        "    def test_consequences_step5_deck_dropped(self):\n",
        "        \"\"\"Test Ex3 Step 5 Consequences: Check final 'deck' NaN count and row count.\"\"\"\n",
        "        print(\"\\nRunning test_consequences_step5_deck_dropped...\")\n",
        "        if self.cleaned_df_final is None:\n",
        "            self.skipTest(\"Ex3 Skipped (Step 5 - Deck Dropped): Final cleaned data not available.\")\n",
        "        if self.original_df is None:\n",
        "            self.skipTest(\"Ex3 Skipped (Step 5 - Deck Dropped): Original data not available for comparison.\")\n",
        "        if 'deck' not in self.original_df.columns:\n",
        "             self.skipTest(\"Ex3 Skipped (Step 5): 'deck' column not in original data.\")\n",
        "\n",
        "        # Assert: Check final 'deck' column NaN count (should be 0)\n",
        "        if 'deck' in self.cleaned_df_final.columns:\n",
        "            final_deck_nan_count = self.cleaned_df_final['deck'].isnull().sum()\n",
        "            self.assertEqual(final_deck_nan_count, 0,\n",
        "                         f\"Step 5 Consequences Assert Failed: Final 'deck' column still has {final_deck_nan_count} NaNs after dropna.\")\n",
        "        else:\n",
        "             # This case shouldn't happen if dropna was run correctly and deck existed originally\n",
        "             self.fail(\"Step 5 Consequences Assert Failed: 'deck' column missing entirely in final data.\")\n",
        "\n",
        "\n",
        "        # Assert: Check final row count against original non-NaN deck count\n",
        "        expected_rows = self.original_df['deck'].notna().sum()\n",
        "        self.assertEqual(len(self.cleaned_df_final), expected_rows,\n",
        "                         f\"Step 5 Consequences Assert Failed: Final row count ({len(self.cleaned_df_final)}) doesn't match original non-NaN deck count ({expected_rows}).\")\n",
        "\n",
        "        # Assert: Check a specific row known to have NaN deck originally is GONE\n",
        "        idx_nan_deck = 0 # Example row\n",
        "        if pd.isna(self.original_df.loc[idx_nan_deck, 'deck']): # Verify assumption\n",
        "            self.assertNotIn(idx_nan_deck, self.cleaned_df_final.index,\n",
        "                            f\"Step 5 Consequences Assert Failed: Row {idx_nan_deck} (orig NaN deck) still present in final data.\")\n",
        "        else:\n",
        "             print(f\"INFO Test Step 5: Original deck at index {idx_nan_deck} was not NaN.\")\n",
        "\n",
        "        print(\"Test test_consequences_step5_deck_dropped PASSED.\")\n",
        "\n",
        "\n",
        "    # --- Optional: Keep a simple integration test as well ---\n",
        "    def test_integration_final_state(self):\n",
        "        \"\"\"Test Ex3 Integration: Simple check on final DataFrame properties.\"\"\"\n",
        "        print(\"\\nRunning test_integration_final_state...\")\n",
        "        if self.cleaned_df_final is None:\n",
        "            self.skipTest(\"Ex3 Skipped (Integration): Final cleaned data not available.\")\n",
        "\n",
        "        # Basic checks on the final state\n",
        "        self.assertIsInstance(self.cleaned_df_final, pd.DataFrame)\n",
        "        self.assertFalse(self.cleaned_df_final.empty)\n",
        "        # Check overall NaN counts for key columns are zero\n",
        "        self.assertEqual(self.cleaned_df_final[['age', 'embarked', 'deck']].isnull().sum().sum(), 0,\n",
        "                         \"Integration Assert Failed: Unexpected NaNs found in final age, embarked, or deck columns.\")\n",
        "        if 'embark_town' in self.cleaned_df_final.columns:\n",
        "             self.assertEqual(self.cleaned_df_final['embark_town'].isnull().sum(), 0,\n",
        "                              \"Integration Assert Failed: Unexpected NaNs found in final embark_town column.\")\n",
        "\n",
        "\n",
        "        print(\"Test test_integration_final_state PASSED.\")\n",
        "\n",
        "display(exercise_3_clean_titanic())\n",
        "# --- Run Tests for Exercise 3 ---\n",
        "run_tests(TestExercise3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "OvsZ9yb-bpEM",
        "outputId": "0825ca68-4330-4b10-91b2-dea4ae0df964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 3 body: Load and clean 'titanic' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running tests from TestExercise3 ---\n",
            "\n",
            "Setting up TestExercise3: Loading original data...\n",
            "\n",
            "Setting up TestExercise3: Running full cleaning function...\n",
            "Setup WARNING: Full cleaning function returned None.\n",
            "test_consequences_step1_age_numeric (__main__.TestExercise3.test_consequences_step1_age_numeric)\n",
            "Test Ex3 Step 1 Consequences: Check final 'age' dtype. ... \n",
            "Running test_consequences_step1_age_numeric...\n",
            "skipped 'Ex3 Skipped (Step 1 - Age Numeric): Final cleaned data not available.'\n",
            "test_consequences_step2_age_filled (__main__.TestExercise3.test_consequences_step2_age_filled)\n",
            "Test Ex3 Step 2 Consequences: Check final 'age' column has no NaNs. ... \n",
            "Running test_consequences_step2_age_filled...\n",
            "skipped 'Ex3 Skipped (Step 2 - Age Filled): Final cleaned data not available.'\n",
            "test_consequences_step3_embarked_filled (__main__.TestExercise3.test_consequences_step3_embarked_filled)\n",
            "Test Ex3 Step 3 Consequences: Check final 'embarked' column has no NaNs. ... \n",
            "Running test_consequences_step3_embarked_filled...\n",
            "skipped 'Ex3 Skipped (Step 3 - Embarked Filled): Final cleaned data not available.'\n",
            "test_consequences_step4_embark_town_filled (__main__.TestExercise3.test_consequences_step4_embark_town_filled)\n",
            "Test Ex3 Step 4 Consequences: Check final 'embark_town' has no NaNs. ... \n",
            "Running test_consequences_step4_embark_town_filled...\n",
            "skipped 'Ex3 Skipped (Step 4 - Embark Town Filled): Final cleaned data not available.'\n",
            "test_consequences_step5_deck_dropped (__main__.TestExercise3.test_consequences_step5_deck_dropped)\n",
            "Test Ex3 Step 5 Consequences: Check final 'deck' NaN count and row count. ... \n",
            "Running test_consequences_step5_deck_dropped...\n",
            "skipped 'Ex3 Skipped (Step 5 - Deck Dropped): Final cleaned data not available.'\n",
            "test_integration_final_state (__main__.TestExercise3.test_integration_final_state)\n",
            "Test Ex3 Integration: Simple check on final DataFrame properties. ... \n",
            "Running test_integration_final_state...\n",
            "skipped 'Ex3 Skipped (Integration): Final cleaned data not available.'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 6 tests in 0.011s\n",
            "\n",
            "OK (skipped=6)\n",
            "--- Finished tests for TestExercise3 ---\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Processing and Filtering / Обработка Текста и Фильтрация"
      ],
      "metadata": {
        "id": "Aej3H9CtrvBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Exercise 4: Text Manipulation and Filtering ---\n",
        "# Note: Renamed 'LastName' to 'category' for clarity, as it's derived from 'who'\n",
        "def exercise_4_text_processing(dataset_name='titanic'):\n",
        "    \"\"\"\n",
        "    Loads the titanic dataset and performs text processing:\n",
        "    1. Create a 'category' column derived from the 'who' column (man, woman, child).\n",
        "    2. Convert the 'category' column to uppercase.\n",
        "    3. Filter the DataFrame to include only entries where 'category' is 'WOMAN'.\n",
        "    4. Further filter for those women who embarked at 'S' (Southampton).\n",
        "    Returns: The filtered DataFrame or None.\n",
        "\n",
        "    Загружает набор данных 'titanic' и выполняет обработку текста:\n",
        "    1. Создает столбец 'category' на основе столбца 'who' (man, woman, child).\n",
        "    2. Преобразует столбец 'category' в верхний регистр.\n",
        "    3. Фильтрует DataFrame, чтобы включить только записи, где 'category' равно 'WOMAN'.\n",
        "    4. Дополнительно фильтрует по тем женщинам, которые сели на борт в 'S' (Саутгемптон).\n",
        "    Возвращает: Отфильтрованный DataFrame или None.\n",
        "\n",
        "    Source: https://www.kaggle.com/c/titanic/data\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Running Exercise 4 body: Load, process text, filter '{dataset_name}' ---\")\n",
        "    try:\n",
        "        df = load_cached_dataset(dataset_name)\n",
        "        if df is None or df.empty:\n",
        "             print(f\"INFO Ex4: Cannot run exercise body: DataFrame '{dataset_name}' is empty or None.\")\n",
        "             return None\n",
        "\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in exercise_4 body: {type(e).__name__} - {e}\")\n",
        "        return None\n",
        "\n",
        "display(exercise_4_text_processing())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "O0kS8BpM0T-D",
        "outputId": "264d61fe-1919-4403-a9ce-a3eefc5604ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 4 body: Load, process text, filter 'titanic' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestExercise4(unittest.TestCase):\n",
        "    # Class level setup\n",
        "    df_filtered = None\n",
        "    original_columns = None\n",
        "\n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        \"\"\"Load and process data once for all tests in this class.\"\"\"\n",
        "        print(\"\\nSetting up TestExercise4: Loading and processing data...\")\n",
        "        # Load original first to get column list\n",
        "        original_df = load_cached_dataset('titanic')\n",
        "        if original_df is not None:\n",
        "            cls.original_columns = original_df.columns.tolist()\n",
        "        else:\n",
        "             print(\"Setup WARNING: Failed to load original titanic data for column check.\")\n",
        "\n",
        "\n",
        "        with contextlib.redirect_stdout(io.StringIO()): # Suppress function prints during setup\n",
        "            cls.df_filtered = exercise_4_text_processing(dataset_name='titanic')\n",
        "\n",
        "        if cls.df_filtered is None:\n",
        "            print(\"Setup WARNING: Failed to process data for TestExercise4.\")\n",
        "        else:\n",
        "             print(f\"Setup INFO: Processed data loaded for TestExercise4 ({len(cls.df_filtered)} rows).\")\n",
        "\n",
        "\n",
        "    def test_ex4_structure_type_columns(self):\n",
        "        \"\"\"Test Ex4: Checks DataFrame type, non-emptiness, expected columns, index type.\"\"\"\n",
        "        print(\"\\nRunning test_ex4_structure_type_columns...\")\n",
        "        if self.df_filtered is None:\n",
        "            self.skipTest(\"Ex4 Skipped (structure): Processed data not available.\")\n",
        "\n",
        "        # Check type\n",
        "        self.assertIsInstance(self.df_filtered, pd.DataFrame, \"Ex4 Result is not a DataFrame\")\n",
        "\n",
        "        # Check non-emptiness (should have results for Titanic)\n",
        "        self.assertFalse(self.df_filtered.empty, \"Ex4 Result DataFrame is unexpectedly empty.\")\n",
        "\n",
        "        # Check columns: should have original columns + new 'category' column\n",
        "        expected_cols = set(self.original_columns or []) | {'category'} # Combine original (if loaded) and new\n",
        "        self.assertSetEqual(set(self.df_filtered.columns), expected_cols, \"Ex4 Column list mismatch\")\n",
        "\n",
        "        # Check index type (boolean filtering preserves original index labels type)\n",
        "        self.assertIsInstance(self.df_filtered.index, pd.Index, \"Ex4 Index is not a pandas Index object\") # General check\n",
        "\n",
        "        print(\"Test test_ex4_structure_type_columns PASSED.\")\n",
        "\n",
        "\n",
        "    def test_ex4_column_content(self):\n",
        "        \"\"\"Test Ex4: Checks content of key columns ('category', 'who', 'embarked').\"\"\"\n",
        "        print(\"\\nRunning test_ex4_column_content...\")\n",
        "        if self.df_filtered is None:\n",
        "            self.skipTest(\"Ex4 Skipped (content): Processed data not available.\")\n",
        "        if self.df_filtered.empty:\n",
        "            self.skipTest(\"Ex4 Skipped (content): Filtered DataFrame is empty, cannot check content.\")\n",
        "\n",
        "        # Check 'category' column is all 'WOMAN'\n",
        "        self.assertTrue(all(self.df_filtered['category'] == 'WOMAN'), \"Ex4 Not all 'category' values are 'WOMAN'\")\n",
        "\n",
        "        # Check 'who' column is all 'woman' (original value check)\n",
        "        if 'who' in self.df_filtered.columns:\n",
        "            self.assertTrue(all(self.df_filtered['who'] == 'woman'), \"Ex4 Not all 'who' values are 'woman'\")\n",
        "        else:\n",
        "             self.fail(\"Ex4 'who' column missing in filtered data, cannot verify.\")\n",
        "\n",
        "\n",
        "        # Check 'embarked' column is all 'S'\n",
        "        self.assertTrue(all(self.df_filtered['embarked'] == 'S'), \"Ex4 Not all 'embarked' values are 'S'\")\n",
        "\n",
        "        print(\"Test test_ex4_column_content PASSED.\")\n",
        "\n",
        "\n",
        "    def test_ex4_row_count(self):\n",
        "        \"\"\"Test Ex4: Checks the final number of rows after filtering.\"\"\"\n",
        "        print(\"\\nRunning test_ex4_row_count...\")\n",
        "        if self.df_filtered is None:\n",
        "            self.skipTest(\"Ex4 Skipped (row count): Processed data not available.\")\n",
        "\n",
        "        # Expected rows: Number of women who embarked at 'S' in the standard Titanic dataset\n",
        "        expected_rows = 174\n",
        "        self.assertEqual(len(self.df_filtered), expected_rows, f\"Ex4 Final filtered row count mismatch. Expected {expected_rows}.\")\n",
        "\n",
        "        print(\"Test test_ex4_row_count PASSED.\")\n",
        "\n",
        "\n",
        "    def test_ex4_data_types(self):\n",
        "        \"\"\"Test Ex4: Checks data types of key columns after processing.\"\"\"\n",
        "        print(\"\\nRunning test_ex4_data_types...\")\n",
        "        if self.df_filtered is None:\n",
        "            self.skipTest(\"Ex4 Skipped (dtypes): Processed data not available.\")\n",
        "\n",
        "        # Check dtypes\n",
        "        self.assertTrue(pd.api.types.is_string_dtype(self.df_filtered['category']), \"Ex4 'category' dtype is not string/object\")\n",
        "        if 'who' in self.df_filtered.columns:\n",
        "             self.assertTrue(pd.api.types.is_string_dtype(self.df_filtered['who']), \"Ex4 'who' dtype is not string/object\")\n",
        "        self.assertTrue(pd.api.types.is_string_dtype(self.df_filtered['embarked']), \"Ex4 'embarked' dtype is not string/object\")\n",
        "        # Check a numeric column stayed numeric\n",
        "        if 'fare' in self.df_filtered.columns:\n",
        "            self.assertTrue(pd.api.types.is_numeric_dtype(self.df_filtered['fare']), \"Ex4 'fare' dtype is not numeric\")\n",
        "        if 'age' in self.df_filtered.columns:\n",
        "            self.assertTrue(pd.api.types.is_numeric_dtype(self.df_filtered['age']), \"Ex4 'age' dtype is not numeric\")\n",
        "\n",
        "        print(\"Test test_ex4_data_types PASSED.\")\n",
        "\n",
        "    def test_ex4_specific_passenger_check(self):\n",
        "        \"\"\"Test Ex4: Checks specific attributes of a known passenger meeting the criteria.\"\"\"\n",
        "        print(\"\\nRunning test_ex4_specific_passenger_check...\")\n",
        "        if self.df_filtered is None:\n",
        "            self.skipTest(\"Ex4 Skipped (specific passenger): Processed data not available.\")\n",
        "\n",
        "        # Find a known passenger: e.g., Passenger ID 3 (original index 2)\n",
        "        # Miss. Laina Heikkinen, Age 26, Embarked S, Survived 1, Pclass 3, Fare 7.925\n",
        "        original_index_label = 2 # The original index label for this passenger\n",
        "\n",
        "        # Check if this passenger is still in the filtered DataFrame (should be)\n",
        "        self.assertIn(original_index_label, self.df_filtered.index, f\"Ex4 Passenger with original index {original_index_label} not found in filtered data.\")\n",
        "\n",
        "        if original_index_label in self.df_filtered.index:\n",
        "            passenger_data = self.df_filtered.loc[original_index_label]\n",
        "\n",
        "            # Verify key attributes\n",
        "            self.assertEqual(passenger_data['who'], 'woman', f\"Ex4 Passenger {original_index_label}: 'who' mismatch\")\n",
        "            self.assertEqual(passenger_data['category'], 'WOMAN', f\"Ex4 Passenger {original_index_label}: 'category' mismatch\")\n",
        "            self.assertEqual(passenger_data['embarked'], 'S', f\"Ex4 Passenger {original_index_label}: 'embarked' mismatch\")\n",
        "            self.assertEqual(passenger_data['pclass'], 3, f\"Ex4 Passenger {original_index_label}: 'pclass' mismatch\")\n",
        "            self.assertEqual(passenger_data['survived'], 1, f\"Ex4 Passenger {original_index_label}: 'survived' mismatch\")\n",
        "            self.assertAlmostEqual(passenger_data['age'], 26.0, places=1, msg=f\"Ex4 Passenger {original_index_label}: 'age' mismatch\")\n",
        "            self.assertAlmostEqual(passenger_data['fare'], 7.925, places=3, msg=f\"Ex4 Passenger {original_index_label}: 'fare' mismatch\")\n",
        "        else:\n",
        "             # This case is covered by assertIn above, but good for clarity\n",
        "             pass\n",
        "\n",
        "        print(\"Test test_ex4_specific_passenger_check PASSED.\")\n",
        "\n",
        "\n",
        "display(exercise_4_text_processing())\n",
        "# --- Run Tests for Exercise 4 ---\n",
        "run_tests(TestExercise4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "ST5F2uSDexSk",
        "outputId": "7f38c232-0b1f-487a-ba63-fb15f7545d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 4 body: Load, process text, filter 'titanic' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running tests from TestExercise4 ---\n",
            "\n",
            "Setting up TestExercise4: Loading and processing data...\n",
            "Setup WARNING: Failed to process data for TestExercise4.\n",
            "test_ex4_column_content (__main__.TestExercise4.test_ex4_column_content)\n",
            "Test Ex4: Checks content of key columns ('category', 'who', 'embarked'). ... \n",
            "Running test_ex4_column_content...\n",
            "skipped 'Ex4 Skipped (content): Processed data not available.'\n",
            "test_ex4_data_types (__main__.TestExercise4.test_ex4_data_types)\n",
            "Test Ex4: Checks data types of key columns after processing. ... \n",
            "Running test_ex4_data_types...\n",
            "skipped 'Ex4 Skipped (dtypes): Processed data not available.'\n",
            "test_ex4_row_count (__main__.TestExercise4.test_ex4_row_count)\n",
            "Test Ex4: Checks the final number of rows after filtering. ... \n",
            "Running test_ex4_row_count...\n",
            "skipped 'Ex4 Skipped (row count): Processed data not available.'\n",
            "test_ex4_specific_passenger_check (__main__.TestExercise4.test_ex4_specific_passenger_check)\n",
            "Test Ex4: Checks specific attributes of a known passenger meeting the criteria. ... \n",
            "Running test_ex4_specific_passenger_check...\n",
            "skipped 'Ex4 Skipped (specific passenger): Processed data not available.'\n",
            "test_ex4_structure_type_columns (__main__.TestExercise4.test_ex4_structure_type_columns)\n",
            "Test Ex4: Checks DataFrame type, non-emptiness, expected columns, index type. ... \n",
            "Running test_ex4_structure_type_columns...\n",
            "skipped 'Ex4 Skipped (structure): Processed data not available.'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 0.010s\n",
            "\n",
            "OK (skipped=5)\n",
            "--- Finished tests for TestExercise4 ---\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grouping and Aggregation / Группировка и Агрегация\n",
        "\n"
      ],
      "metadata": {
        "id": "5PEA8SeqrzlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Exercise 5: Grouping and Aggregation ---\n",
        "def exercise_5_group_aggregate():\n",
        "    \"\"\"\n",
        "    Loads the tips dataset and performs grouping and aggregation:\n",
        "    1. Group the data by 'day' and 'smoker'. Use observed=False for consistency.\n",
        "    2. Calculate the following aggregations for each group:\n",
        "        - Average 'total_bill' (mean)\n",
        "        - Maximum 'tip' (max)\n",
        "        - Total number of entries in the group, tip (size)\n",
        "    3. The aggregated columns should be named 'avg_bill', 'max_tip', and 'count'.\n",
        "    Returns: The aggregated DataFrame with renamed columns or None.\n",
        "\n",
        "    Загружает набор данных tips и выполняет группировку и агрегацию:\n",
        "    1. Группирует данные по 'day' и 'smoker'. Используйте observed=False для согласованности.\n",
        "    2. Вычисляет следующие агрегации для каждой группы:\n",
        "        - Среднее значение 'total_bill' (mean)\n",
        "        - Максимальное значение 'tip' (max)\n",
        "        - Общее количество записей в группе (size)\n",
        "    3. Агрегированные столбцы должны быть названы 'avg_bill', 'max_tip', и 'count'.\n",
        "    Возвращает: Агрегированный DataFrame с переименованными столбцами или None.\n",
        "\n",
        "    Source: https://rdrr.io/cran/reshape2/man/tips.html\n",
        "    \"\"\"\n",
        "    dataset_name='tips'\n",
        "    print(f\"\\n--- Running Exercise 5 body: Load, group, aggregate '{dataset_name}' ---\")\n",
        "    try:\n",
        "        df = load_cached_dataset(dataset_name)\n",
        "        df_processed = df.copy()\n",
        "\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in exercise_5 body: {type(e).__name__} - {e}\")\n",
        "        return None\n",
        "\n",
        "display(exercise_5_group_aggregate())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "gxat5eOJ0Yt_",
        "outputId": "9796882b-91e1-467e-aa54-c7737ef39fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 5 body: Load, group, aggregate 'tips' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestExercise5(unittest.TestCase):\n",
        "    # Class level setup to load data once for all tests in this class\n",
        "    df_agg = None\n",
        "\n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        \"\"\"Load the aggregated data once before all tests in this class.\"\"\"\n",
        "        print(\"\\nSetting up TestExercise5: Loading aggregated data...\")\n",
        "        with contextlib.redirect_stdout(io.StringIO()): # Suppress function prints during setup\n",
        "             cls.df_agg = exercise_5_group_aggregate()\n",
        "        if cls.df_agg is None:\n",
        "            print(\"Setup WARNING: Failed to load aggregated data for TestExercise5.\")\n",
        "            # Tests will likely be skipped by the skipIf decorator\n",
        "\n",
        "    def test_ex5_structure_and_basic_values(self):\n",
        "        \"\"\"Test Ex5: Checks type, index, columns, group count, and basic values.\"\"\"\n",
        "        print(\"\\nRunning test_ex5_structure_and_basic_values...\")\n",
        "        if self.df_agg is None:\n",
        "            self.skipTest(\"Ex5 Skipped (structure/basic): Aggregated data not loaded.\")\n",
        "\n",
        "        # Check type and structure\n",
        "        self.assertIsInstance(self.df_agg, pd.DataFrame, \"Ex5 Result is not a DataFrame\")\n",
        "        self.assertIsInstance(self.df_agg.index, pd.MultiIndex, \"Ex5 Result index is not a MultiIndex\")\n",
        "        self.assertEqual(self.df_agg.index.names, ['day', 'smoker'], \"Ex5 Index names are incorrect\")\n",
        "\n",
        "        # Check column names\n",
        "        expected_cols = ['avg_bill', 'max_tip', 'count']\n",
        "        self.assertListEqual(self.df_agg.columns.tolist(), expected_cols, \"Ex5 Column names mismatch\")\n",
        "\n",
        "        # Check number of groups (4 days * 2 smoker statuses = 8)\n",
        "        self.assertEqual(len(self.df_agg), 8, \"Ex5 Number of groups mismatch\")\n",
        "\n",
        "        # Check specific aggregated values (use .loc with tuple for MultiIndex)\n",
        "        try:\n",
        "            # Thursday smokers\n",
        "            thurs_smoker = self.df_agg.loc[('Thur', 'Yes')]\n",
        "            self.assertAlmostEqual(thurs_smoker['avg_bill'], 19.190588, places=4, msg=\"Ex5 Thur/Yes avg_bill mismatch\")\n",
        "            self.assertEqual(thurs_smoker['max_tip'], 5.00, msg=\"Ex5 Thur/Yes max_tip mismatch\")\n",
        "            self.assertEqual(thurs_smoker['count'], 17, msg=\"Ex5 Thur/Yes count mismatch\")\n",
        "\n",
        "            # Sunday non-smokers\n",
        "            sun_nosmoker = self.df_agg.loc[('Sun', 'No')]\n",
        "            self.assertAlmostEqual(sun_nosmoker['avg_bill'], 20.506667, places=4, msg=\"Ex5 Sun/No avg_bill mismatch\")\n",
        "            self.assertEqual(sun_nosmoker['max_tip'], 6.00, msg=\"Ex5 Sun/No max_tip mismatch\")\n",
        "            self.assertEqual(sun_nosmoker['count'], 57, msg=\"Ex5 Sun/No count mismatch\")\n",
        "        except KeyError as e:\n",
        "            self.fail(f\"Ex5 Failed to access group in MultiIndex during basic checks: {e}\")\n",
        "\n",
        "        print(\"Test test_ex5_structure_and_basic_values PASSED.\")\n",
        "\n",
        "    def test_ex5_data_types(self):\n",
        "        \"\"\"Test Ex5: Checks the data types of the aggregated columns.\"\"\"\n",
        "        print(\"\\nRunning test_ex5_data_types...\")\n",
        "        if self.df_agg is None:\n",
        "            self.skipTest(\"Ex5 Skipped (dtypes): Aggregated data not loaded.\")\n",
        "\n",
        "        # Check dtypes\n",
        "        self.assertTrue(pd.api.types.is_float_dtype(self.df_agg['avg_bill']), \"Ex5 'avg_bill' dtype is not float\")\n",
        "        # max_tip could be float or int depending on original data, check for numeric\n",
        "        self.assertTrue(pd.api.types.is_numeric_dtype(self.df_agg['max_tip']), \"Ex5 'max_tip' dtype is not numeric\")\n",
        "        self.assertTrue(pd.api.types.is_integer_dtype(self.df_agg['count']), \"Ex5 'count' dtype is not integer\")\n",
        "        print(\"Test test_ex5_data_types PASSED.\")\n",
        "\n",
        "    def test_ex5_non_nullness(self):\n",
        "        \"\"\"Test Ex5: Checks that aggregated columns do not contain null values.\"\"\"\n",
        "        print(\"\\nRunning test_ex5_non_nullness...\")\n",
        "        if self.df_agg is None:\n",
        "            self.skipTest(\"Ex5 Skipped (non-null): Aggregated data not loaded.\")\n",
        "\n",
        "        # Check for NaNs - shouldn't occur with mean/max/size on this dataset unless a group was truly empty\n",
        "        self.assertFalse(self.df_agg['avg_bill'].isnull().any(), \"Ex5 'avg_bill' contains NaN values\")\n",
        "        self.assertFalse(self.df_agg['max_tip'].isnull().any(), \"Ex5 'max_tip' contains NaN values\")\n",
        "        self.assertFalse(self.df_agg['count'].isnull().any(), \"Ex5 'count' contains NaN values\")\n",
        "        print(\"Test test_ex5_non_nullness PASSED.\")\n",
        "\n",
        "    def test_ex5_index_uniqueness(self):\n",
        "        \"\"\"Test Ex5: Checks if the MultiIndex is unique.\"\"\"\n",
        "        print(\"\\nRunning test_ex5_index_uniqueness...\")\n",
        "        if self.df_agg is None:\n",
        "            self.skipTest(\"Ex5 Skipped (index unique): Aggregated data not loaded.\")\n",
        "\n",
        "        self.assertTrue(self.df_agg.index.is_unique, \"Ex5 MultiIndex is not unique\")\n",
        "        print(\"Test test_ex5_index_uniqueness PASSED.\")\n",
        "\n",
        "    def test_ex5_more_group_values(self):\n",
        "        \"\"\"Test Ex5: Checks specific values for additional groups.\"\"\"\n",
        "        print(\"\\nRunning test_ex5_more_group_values...\")\n",
        "        if self.df_agg is None:\n",
        "            self.skipTest(\"Ex5 Skipped (more groups): Aggregated data not loaded.\")\n",
        "\n",
        "        try:\n",
        "            # Friday smokers\n",
        "            fri_smoker = self.df_agg.loc[('Fri', 'Yes')]\n",
        "            self.assertAlmostEqual(fri_smoker['avg_bill'], 16.813333, places=4, msg=\"Ex5 Fri/Yes avg_bill mismatch\")\n",
        "            self.assertEqual(fri_smoker['max_tip'], 4.73, msg=\"Ex5 Fri/Yes max_tip mismatch\")\n",
        "            self.assertEqual(fri_smoker['count'], 15, msg=\"Ex5 Fri/Yes count mismatch\")\n",
        "\n",
        "            # Saturday non-smokers\n",
        "            sat_nosmoker = self.df_agg.loc[('Sat', 'No')]\n",
        "            self.assertAlmostEqual(sat_nosmoker['avg_bill'], 19.661778, places=4, msg=\"Ex5 Sat/No avg_bill mismatch\")\n",
        "            self.assertEqual(sat_nosmoker['max_tip'], 9.00, msg=\"Ex5 Sat/No max_tip mismatch\")\n",
        "            self.assertEqual(sat_nosmoker['count'], 45, msg=\"Ex5 Sat/No count mismatch\")\n",
        "        except KeyError as e:\n",
        "            self.fail(f\"Ex5 Failed to access group in MultiIndex during more group checks: {e}\")\n",
        "\n",
        "        print(\"Test test_ex5_more_group_values PASSED.\")\n",
        "\n",
        "# --- Run Tests for Exercise 5 ---\n",
        "display(exercise_5_group_aggregate())\n",
        "run_tests(TestExercise5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "tL0bpMX7oLr-",
        "outputId": "bff5bb56-e6ff-4c83-afe8-1a383f2bfff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 5 body: Load, group, aggregate 'tips' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running tests from TestExercise5 ---\n",
            "\n",
            "Setting up TestExercise5: Loading aggregated data...\n",
            "Setup WARNING: Failed to load aggregated data for TestExercise5.\n",
            "test_ex5_data_types (__main__.TestExercise5.test_ex5_data_types)\n",
            "Test Ex5: Checks the data types of the aggregated columns. ... \n",
            "Running test_ex5_data_types...\n",
            "skipped 'Ex5 Skipped (dtypes): Aggregated data not loaded.'\n",
            "test_ex5_index_uniqueness (__main__.TestExercise5.test_ex5_index_uniqueness)\n",
            "Test Ex5: Checks if the MultiIndex is unique. ... \n",
            "Running test_ex5_index_uniqueness...\n",
            "skipped 'Ex5 Skipped (index unique): Aggregated data not loaded.'\n",
            "test_ex5_more_group_values (__main__.TestExercise5.test_ex5_more_group_values)\n",
            "Test Ex5: Checks specific values for additional groups. ... \n",
            "Running test_ex5_more_group_values...\n",
            "skipped 'Ex5 Skipped (more groups): Aggregated data not loaded.'\n",
            "test_ex5_non_nullness (__main__.TestExercise5.test_ex5_non_nullness)\n",
            "Test Ex5: Checks that aggregated columns do not contain null values. ... \n",
            "Running test_ex5_non_nullness...\n",
            "skipped 'Ex5 Skipped (non-null): Aggregated data not loaded.'\n",
            "test_ex5_structure_and_basic_values (__main__.TestExercise5.test_ex5_structure_and_basic_values)\n",
            "Test Ex5: Checks type, index, columns, group count, and basic values. ... \n",
            "Running test_ex5_structure_and_basic_values...\n",
            "skipped 'Ex5 Skipped (structure/basic): Aggregated data not loaded.'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 0.011s\n",
            "\n",
            "OK (skipped=5)\n",
            "--- Finished tests for TestExercise5 ---\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Car Name Extraction and Cleaning / Извлечение и Очистка Названий Автомобилей"
      ],
      "metadata": {
        "id": "tzyMEAQtuLvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Exercise 6: Extracting and Cleaning Car Names ---\n",
        "def exercise_6_process_car_names():\n",
        "    \"\"\"\n",
        "    Loads the MPG dataset and processes the 'name' column:\n",
        "    1. Creates a new column 'intial_brand' by extracting the first word from the 'name' column.\n",
        "       (Assumption: first word is the brand). Handles potential errors during extraction.\n",
        "    2. Create a column 'brand' from 'intial_brand' using .str.replace() or map and lambda:\n",
        "        - Replaces 'chevy' and 'chevroelt' with 'chevrolet'.\n",
        "        - Replaces 'maxda' with 'mazda'.\n",
        "        - Replaces 'mercedes-benz' with 'mercedes'.\n",
        "        - Replaces 'vw' and 'vokswagen' with 'volkswagen'.\n",
        "    3. Creates a new column 'cleaned_name' by removing the brand (the first word)\n",
        "       and any leading/trailing whitespace from the original 'name'.\n",
        "\n",
        "    Use:\n",
        "    1) Accessor .str\n",
        "    2) Method .str[n] for accessing elements of a massive\n",
        "    3) .str.join for joining the string back together\n",
        "\n",
        "    Returns: The DataFrame with the new 'brand' and 'cleaned_name' columns or None.\n",
        "\n",
        "    Загружает набор данных MPG и обрабатывает столбец 'name':\n",
        "    1. Создает новый столбец 'intial_brand' путем извлечения первого слова из столбца 'name'.\n",
        "    (Предположение: первое слово - это бренд). Обрабатывает возможные ошибки при извлечении.\n",
        "    2. Создайте колонку 'brand' из 'initial_brand' c помощью .str.replace() или map и lambda:\n",
        "        - Заменяет 'chevy' и 'chevroelt' на 'chevrolet'.\n",
        "        - Заменяет 'maxda' на 'mazda'.\n",
        "        - Заменяет 'mercedes-benz' на 'mercedes'.\n",
        "        - Заменяет 'vw' и 'vokswagen' на 'volkswagen'.\n",
        "    3. Создает новый столбец 'cleaned_name', удаляя бренд (первое слово) и любые начальные/конечные пробелы из исходного столбца 'name'.\n",
        "\n",
        "    Успользуй\n",
        "    1) эксесор .str\n",
        "    2) .str для получения элемнта в массиве (включая слайсы)\n",
        "    3) .str.join для соединения массива в строку\n",
        "\n",
        "    Возвращает: DataFrame с новыми столбцами 'brand' и 'cleaned_name' или None.\n",
        "    \"\"\"\n",
        "    dataset_name='mpg'\n",
        "    print(f\"\\n--- Running Exercise 6 body: Load '{dataset_name}', process car names ---\")\n",
        "    try:\n",
        "        df = load_cached_dataset(dataset_name)\n",
        "        if df is None or df.empty:\n",
        "            print(f\"INFO Ex6: Cannot run exercise body: DataFrame '{dataset_name}' is empty or None.\")\n",
        "            return None\n",
        "\n",
        "        df_processed = df.copy()\n",
        "\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in exercise_6 body: {type(e).__name__} - {e}\")\n",
        "        return None\n",
        "\n",
        "display(exercise_6_process_car_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "PLjC2g1L0f4H",
        "outputId": "c9ebc61a-289c-4bab-aefc-f0d2546250bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 6 body: Load 'mpg', process car names ---\n",
            "\n",
            "Attempting to load dataset 'mpg'...\n",
            "Dataset 'mpg' loaded successfully (398 rows, 9 cols).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Tests for Exercise 6 ---\n",
        "class TestExercise6(unittest.TestCase):\n",
        "    original_df = None\n",
        "    result_df = None\n",
        "    test_indices = {\n",
        "        # name_key: index # original 'name' value from dataset\n",
        "        'chevrolet_ok': 0,      # 'chevrolet malibu'\n",
        "        'chevrolet_typo1': 26,  # 'chevy c20'\n",
        "        'chevrolet_typo2': 161, # 'chevroelt chevelle malibu'\n",
        "        'mazda_typo': 294,      # 'maxda glc deluxe'\n",
        "        'vw_typo1': 394,        # 'vw pickup'\n",
        "        'vw_typo2': 309,        # 'vokswagen rabbit'\n",
        "        'mercedes_hyphen': 211, # 'mercedes-benz 280s'\n",
        "        'toyota_ok': 31,        # 'toyota corona mark ii'\n",
        "        'ford_ok': 32,          # 'ford pinto'\n",
        "        'multi_space': 97,     # 'plymouth valiant'\n",
        "        'single_word': 100,     # 'hi 1200d'\n",
        "        'nan_name': None        # Placeholder for index with NaN name if one exists\n",
        "    }\n",
        "\n",
        "    # Expected values are the *first word* of the original name string\n",
        "    initial_brand_test_cases = {\n",
        "            'chevrolet_ok': 'chevrolet',\n",
        "            'chevrolet_typo1': 'chevy',\n",
        "            'chevrolet_typo2': 'chevroelt',\n",
        "            'mazda_typo': 'maxda',\n",
        "            'vw_typo1': 'vw',\n",
        "            'vw_typo2': 'vokswagen',\n",
        "            'mercedes_hyphen': 'mercedes-benz',\n",
        "            'toyota_ok': 'toyota',\n",
        "            'ford_ok': 'ford',\n",
        "            'single_word': 'hi', # First word of 'hi 1200d'\n",
        "        }\n",
        "\n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        \"\"\"Load original data and run the exercise function once.\"\"\"\n",
        "        print(\"\\nSetting up TestExercise6: Loading original mpg data and running function...\")\n",
        "        cls.original_df = load_cached_dataset('mpg')\n",
        "\n",
        "        # Update test indices based on loaded data if possible\n",
        "        # This makes tests less brittle if the dataset has slight variations\n",
        "        if cls.original_df is not None:\n",
        "            name_col = cls.original_df['name']\n",
        "            idx_map = {\n",
        "                'chevrolet_ok': name_col[name_col == 'chevrolet malibu'].index,\n",
        "                'chevrolet_typo1': name_col[name_col == 'chevy c20'].index,\n",
        "                'chevrolet_typo2': name_col[name_col == 'chevroelt chevelle malibu'].index,\n",
        "                'mazda_typo': name_col[name_col == 'maxda glc deluxe'].index,\n",
        "                'vw_typo1': name_col[name_col == 'vw pickup'].index,\n",
        "                'vw_typo2': name_col[name_col == 'vokswagen rabbit'].index,\n",
        "                'mercedes_hyphen': name_col[name_col == 'mercedes-benz 280s'].index,\n",
        "                'toyota_ok': name_col[name_col == 'toyota corona mark ii'].index,\n",
        "                'ford_ok': name_col[name_col == 'ford pinto'].index,\n",
        "                'multi_space': name_col[name_col == 'plymouth valiant'].index, # No trailing space usually\n",
        "                'single_word': name_col[name_col == 'hi 1200d'].index,\n",
        "            }\n",
        "            for name, found_indices in idx_map.items():\n",
        "                if not found_indices.empty:\n",
        "                    cls.test_indices[name] = found_indices[0] # Take the first match\n",
        "                else:\n",
        "                     print(f\"WARN Setup: Could not find index for test case '{name}' in loaded data.\")\n",
        "                     cls.test_indices[name] = None # Mark as not found\n",
        "\n",
        "            # Find or add NaN\n",
        "            nan_indices = cls.original_df[cls.original_df['name'].isna()].index\n",
        "            if not nan_indices.empty:\n",
        "                cls.test_indices['nan_name'] = nan_indices[0]\n",
        "                print(f\"INFO: Found existing NaN in 'name' at index {cls.test_indices['nan_name']}.\")\n",
        "\n",
        "        else:\n",
        "             print(\"Setup WARNING: Original MPG data failed to load. Some tests may be skipped or use fallback indices.\")\n",
        "\n",
        "\n",
        "        # Run the function (which loads its own data)\n",
        "        with contextlib.redirect_stdout(io.StringIO()):\n",
        "            cls.result_df = exercise_6_process_car_names() # Function loads 'mpg' internally\n",
        "\n",
        "        if cls.result_df is None:\n",
        "            print(\"Setup WARNING: Exercise 6 function returned None.\")\n",
        "        elif cls.original_df is not None and len(cls.result_df) != len(cls.original_df):\n",
        "             print(f\"Setup WARNING: Row count mismatch between original ({len(cls.original_df)}) and result ({len(cls.result_df)}).\")\n",
        "        elif 'cleaned_name' not in cls.result_df.columns:\n",
        "             print(\"Setup WARNING: 'cleaned_name' column is missing from the result (likely Step 3 not implemented).\")\n",
        "\n",
        "\n",
        "    def test_ex6_structure_columns(self):\n",
        "        \"\"\"Test Ex6: Checks result type, existence and non-emptiness of new columns.\"\"\"\n",
        "        print(\"\\nRunning test_ex6_structure_columns...\")\n",
        "        if self.result_df is None:\n",
        "            self.skipTest(\"Ex6 Skipped (structure): Result data not available (function returned None).\")\n",
        "\n",
        "        self.assertIsInstance(self.result_df, pd.DataFrame, \"Ex6 Result is not a DataFrame.\")\n",
        "\n",
        "        # Check new columns exist\n",
        "        self.assertIn('brand', self.result_df.columns, \"Ex6 Column 'brand' is missing.\")\n",
        "        # Check 'cleaned_name' exists, even if it's just the placeholder NaN column\n",
        "        self.assertIn('cleaned_name', self.result_df.columns, \"Ex6 Column 'cleaned_name' is missing (placeholder expected if Step 3 not done).\")\n",
        "\n",
        "        # Check columns are not empty (assuming original dataset isn't empty)\n",
        "        if self.original_df is not None and not self.original_df.empty:\n",
        "            if 'brand' in self.result_df.columns:\n",
        "                 self.assertFalse(self.result_df['brand'].isnull().all(), \"Ex6 Column 'brand' is entirely null.\")\n",
        "\n",
        "        # Check shape (should be same number of rows as original)\n",
        "        if self.original_df is not None:\n",
        "            self.assertEqual(len(self.result_df), len(self.original_df),\n",
        "                             f\"Ex6 Row count changed unexpectedly. Original={len(self.original_df)}, Result={len(self.result_df)}\")\n",
        "\n",
        "        print(\"Test test_ex6_structure_columns PASSED.\")\n",
        "\n",
        "    def test_ex6_initial_brand_extraction(self):\n",
        "        \"\"\"Test Ex6 Step 1: Checks 'brand' column *before* cleaning (contains original first word).\"\"\"\n",
        "        print(\"\\nRunning test_ex6_initial_brand_extraction...\")\n",
        "        if self.result_df is None:\n",
        "            self.skipTest(\"Ex6 Skipped (initial brand): Result data not available.\")\n",
        "        if 'initial_brand' not in self.result_df.columns:\n",
        "             self.fail(\"Ex6 Prerequisite Fail (initial brand): 'initial_brand' column missing.\")\n",
        "\n",
        "        for name, expected_initial_brand in self.initial_brand_test_cases.items():\n",
        "             idx = self.test_indices.get(name)\n",
        "             if idx is None:\n",
        "                 print(f\"WARN (initial brand): Test index for '{name}' not found, skipping check.\")\n",
        "                 continue\n",
        "             if idx not in self.result_df.index:\n",
        "                  self.fail(f\"Ex6 Test Fail (initial brand): Index {idx} for '{name}' not found in result DataFrame.\")\n",
        "\n",
        "             actual_brand = self.result_df.loc[idx, 'initial_brand']\n",
        "             self.assertEqual(actual_brand, expected_initial_brand,\n",
        "                              f\"Ex6 Initial Brand incorrect for index {idx} (case: '{name}'). Expected first word '{expected_initial_brand}', got '{actual_brand}'.\")\n",
        "\n",
        "        print(\"Test test_ex6_initial_brand_extraction PASSED.\")\n",
        "\n",
        "\n",
        "    def test_ex6_brand_extraction_and_cleaning(self):\n",
        "        \"\"\"Test Ex6 Step 2: Checks specific 'brand' values *after* extraction and replacement.\"\"\"\n",
        "        print(\"\\nRunning test_ex6_brand_extraction_and_cleaning...\")\n",
        "        if self.result_df is None:\n",
        "            self.skipTest(\"Ex6 Skipped (brand cleaning): Result data not available.\")\n",
        "        if 'brand' not in self.result_df.columns:\n",
        "             self.fail(\"Ex6 Prerequisite Fail (brand cleaning): 'brand' column missing.\")\n",
        "\n",
        "        # This test assumes Step 2 (replacement) has been implemented in the function\n",
        "        cleaned_brand_test_cases = {\n",
        "            # name_key: (expected_CLEANED_brand, original_full_name for context)\n",
        "            'chevrolet_ok': ('chevrolet', 'chevrolet malibu'),\n",
        "            'chevrolet_typo1': ('chevrolet', 'chevy c20'),\n",
        "            'chevrolet_typo2': ('chevrolet', 'chevroelt chevelle malibu'),\n",
        "            'mazda_typo': ('mazda', 'maxda glc deluxe'),\n",
        "            'vw_typo1': ('volkswagen', 'vw pickup'),\n",
        "            'vw_typo2': ('volkswagen', 'vokswagen rabbit'),\n",
        "            'mercedes_hyphen': ('mercedes', 'mercedes-benz 280s'),\n",
        "            'toyota_ok': ('toyota', 'toyota corona mark ii'), # No cleaning needed\n",
        "            'ford_ok': ('ford', 'ford pinto'),             # No cleaning needed\n",
        "            'single_word': ('hi', 'hi 1200d'), # Brand 'hi' requires no cleaning\n",
        "        }\n",
        "\n",
        "        failures = []\n",
        "        for name, (expected_brand, original_name) in cleaned_brand_test_cases.items():\n",
        "             idx = self.test_indices.get(name)\n",
        "             if idx is None:\n",
        "                 print(f\"WARN (brand cleaning): Test index for '{name}' not found, skipping check.\")\n",
        "                 continue\n",
        "             if idx not in self.result_df.index:\n",
        "                  failures.append(f\"Index {idx} for '{name}' not found in result DataFrame.\")\n",
        "                  continue\n",
        "\n",
        "             actual_brand = self.result_df.loc[idx, 'brand']\n",
        "             try:\n",
        "                self.assertEqual(actual_brand, expected_brand)\n",
        "             except AssertionError:\n",
        "                 failures.append(f\"Brand incorrect for index {idx} (orig: '{original_name}'). Expected CLEANED '{expected_brand}', got '{actual_brand}'.\")\n",
        "\n",
        "\n",
        "        if failures:\n",
        "             # Check if failures match the initial extraction (meaning Step 2 likely wasn't run)\n",
        "             initial_values = {idx: self.result_df.loc[idx, 'brand'] for idx in self.test_indices.values() if idx is not None and idx in self.result_df.index}\n",
        "             step1_only = all(\n",
        "                  initial_values.get(self.test_indices.get(name)) == actual\n",
        "                  for name, (expected, orig) in cleaned_brand_test_cases.items()\n",
        "                  if self.test_indices.get(name) is not None and name in self.initial_brand_test_cases # compare where applicable\n",
        "                  for actual in [self.result_df.loc[self.test_indices.get(name), 'brand']] # Get actual value once\n",
        "                  if actual != expected # Check only failing cases\n",
        "             )\n",
        "\n",
        "             if step1_only and len(failures) > 0 :\n",
        "                  self.skipTest(f\"Ex6 Skipped (brand cleaning): Failures detected, likely because Step 2 (replacement) is not implemented. Failures:\\n\" + \"\\n\".join(failures))\n",
        "             else:\n",
        "                  self.fail(\"Ex6 Test Fail (brand cleaning):\\n\" + \"\\n\".join(failures))\n",
        "        else:\n",
        "            print(\"Test test_ex6_brand_extraction_and_cleaning PASSED.\")\n",
        "\n",
        "\n",
        "    def test_ex6_cleaned_name_creation(self):\n",
        "        \"\"\"Test Ex6 Step 3: Checks specific 'cleaned_name' values (removal of *original* first word).\"\"\"\n",
        "        print(\"\\nRunning test_ex6_cleaned_name_creation...\")\n",
        "        if self.result_df is None:\n",
        "            self.skipTest(\"Ex6 Skipped (cleaned_name creation): Result data not available.\")\n",
        "        if 'cleaned_name' not in self.result_df.columns:\n",
        "             self.fail(\"Ex6 Prerequisite Fail (cleaned_name creation): 'cleaned_name' column missing.\")\n",
        "        # Check if the column is just the placeholder NaN column\n",
        "        if self.result_df['cleaned_name'].isnull().all():\n",
        "            self.skipTest(\"Ex6 Skipped (cleaned_name creation): 'cleaned_name' column contains only NaNs (likely Step 3 not implemented).\")\n",
        "\n",
        "\n",
        "        # This test assumes Step 3 has been implemented in the function\n",
        "        cleaned_name_test_cases = {\n",
        "            # name_key: (expected_cleaned_name, original_full_name for context)\n",
        "            'chevrolet_ok': ('malibu', 'chevrolet malibu'),\n",
        "            'toyota_ok': ('corona mark ii', 'toyota corona mark ii'),\n",
        "            'ford_ok': ('pinto', 'ford pinto'),\n",
        "            'chevrolet_typo2': ('chevelle malibu', 'chevroelt chevelle malibu'), # Should remove 'chevroelt'\n",
        "            'mazda_typo': ('glc deluxe', 'maxda glc deluxe'),  # Should remove 'maxda'\n",
        "            'vw_typo1': ('pickup', 'vw pickup'),              # Should remove 'vw'\n",
        "            'mercedes_hyphen': ('280s', 'mercedes-benz 280s'), # Should remove 'mercedes-benz'\n",
        "            'multi_space': ('valiant', 'plymouth valiant'), # Assumes stripping occurs\n",
        "            'single_word': ('1200d', 'hi 1200d'), # Should remove 'hi'\n",
        "        }\n",
        "\n",
        "        failures = []\n",
        "        for name, (expected_cleaned, original_name) in cleaned_name_test_cases.items():\n",
        "             idx = self.test_indices.get(name)\n",
        "             if idx is None:\n",
        "                 print(f\"WARN (cleaned_name creation): Test index for '{name}' not found, skipping check.\")\n",
        "                 continue\n",
        "             if idx not in self.result_df.index:\n",
        "                  failures.append(f\"Index {idx} for '{name}' not found in result DataFrame.\")\n",
        "                  continue\n",
        "\n",
        "             actual_cleaned = self.result_df.loc[idx, 'cleaned_name']\n",
        "             try:\n",
        "                 self.assertEqual(actual_cleaned, expected_cleaned)\n",
        "             except AssertionError:\n",
        "                  failures.append(f\"cleaned_name incorrect for index {idx} (orig: '{original_name}'). Expected '{expected_cleaned}', got '{actual_cleaned}'.\")\n",
        "\n",
        "        if failures:\n",
        "             self.fail(\"Ex6 Test Fail (cleaned_name creation):\\n\" + \"\\n\".join(failures))\n",
        "        else:\n",
        "             print(\"Test test_ex6_cleaned_name_creation PASSED.\")\n",
        "\n",
        "\n",
        "    def test_ex6_data_types(self):\n",
        "        \"\"\"Test Ex6: Checks the data types of the new columns.\"\"\"\n",
        "        print(\"\\nRunning test_ex6_data_types...\")\n",
        "        if self.result_df is None:\n",
        "            self.skipTest(\"Ex6 Skipped (dtypes): Result data not available.\")\n",
        "        if 'brand' not in self.result_df.columns or 'cleaned_name' not in self.result_df.columns:\n",
        "             self.fail(\"Ex6 Prerequisite Fail (dtypes): 'brand' or 'cleaned_name' column missing.\")\n",
        "\n",
        "        # Brand should ideally be string (object or pandas StringDtype)\n",
        "        self.assertTrue(pd.api.types.is_string_dtype(self.result_df['brand'].dtype) or pd.api.types.is_object_dtype(self.result_df['brand'].dtype) ,\n",
        "                        f\"Ex6 'brand' dtype is not string/object. Found: {self.result_df['brand'].dtype}\")\n",
        "\n",
        "        # Allow cleaned_name to be object or float if it contains NaNs (esp if Step 3 not run or if single words existed)\n",
        "        is_str_or_obj = pd.api.types.is_string_dtype(self.result_df['cleaned_name'].dtype) or \\\n",
        "                        pd.api.types.is_object_dtype(self.result_df['cleaned_name'].dtype)\n",
        "        self.assertTrue(is_str_or_obj or self.result_df['cleaned_name'].isnull().all(),\n",
        "                        f\"Ex6 'cleaned_name' dtype is not string/object (and not all null). Found: {self.result_df['cleaned_name'].dtype}\")\n",
        "\n",
        "        print(\"Test test_ex6_data_types PASSED.\")\n",
        "\n",
        "    def test_ex6_other_columns_unchanged(self):\n",
        "        \"\"\"Test Ex6: Checks that columns other than 'brand' and 'cleaned_name' are identical to original.\"\"\"\n",
        "        print(\"\\nRunning test_ex6_other_columns_unchanged...\")\n",
        "        if self.result_df is None:\n",
        "            self.skipTest(\"Ex6 Skipped (unchanged cols): Result data not available.\")\n",
        "        if self.original_df is None:\n",
        "            self.skipTest(\"Ex6 Skipped (unchanged cols): Original data not available for comparison.\")\n",
        "        if len(self.result_df) != len(self.original_df):\n",
        "             self.skipTest(\"Ex6 Skipped (unchanged cols): Row count mismatch prevents reliable comparison.\")\n",
        "\n",
        "        original_cols = list(self.original_df.columns)\n",
        "        new_cols = ['brand', 'cleaned_name']\n",
        "        other_cols = [col for col in original_cols if col not in new_cols and col != 'name'] # Exclude 'name' too\n",
        "\n",
        "        # Ensure these columns still exist in the result\n",
        "        missing_cols = [col for col in other_cols if col not in self.result_df.columns]\n",
        "        if missing_cols:\n",
        "             self.fail(f\"Ex6 Unchanged Cols Fail: The following original columns are missing from the result: {missing_cols}\")\n",
        "\n",
        "        # Compare the DataFrames subsetted to these columns\n",
        "        # Use reset_index to compare values even if index was altered (though it shouldn't be)\n",
        "        # Handle potential dtype changes if NaNs were introduced/removed in compared columns (unlikely here)\n",
        "        try:\n",
        "            pd.testing.assert_frame_equal(\n",
        "                self.original_df[other_cols].reset_index(drop=True),\n",
        "                self.result_df[other_cols].reset_index(drop=True),\n",
        "                check_dtype=True, # Be strict about dtypes\n",
        "                check_like=True # Ensure column order and index type match (after reset)\n",
        "            )\n",
        "        except AssertionError as e:\n",
        "            # Provide more specific feedback about where the difference lies\n",
        "            diff_summary = []\n",
        "            df1 = self.original_df[other_cols].reset_index(drop=True)\n",
        "            df2 = self.result_df[other_cols].reset_index(drop=True)\n",
        "            for col in other_cols:\n",
        "                if not df1[col].equals(df2[col]):\n",
        "                    diff_indices = df1.index[df1[col] != df2[col]]\n",
        "                    diff_summary.append(f\"Column '{col}' differs at indices: {list(diff_indices[:5])}...\") # Show first few diffs\n",
        "\n",
        "            self.fail(f\"Ex6 Unchanged Cols Fail: DataFrame comparison failed for columns {other_cols}.\\nDetails:\\n{e}\\nSummary of differences:\\n\" + \"\\n\".join(diff_summary))\n",
        "        except Exception as e:\n",
        "             self.fail(f\"Ex6 Unchanged Cols Fail: Error during comparison of columns {other_cols}.\\nDetails: {type(e).__name__} - {e}\")\n",
        "\n",
        "\n",
        "        print(\"Test test_ex6_other_columns_unchanged PASSED.\")\n",
        "\n",
        "\n",
        "# --- Run Tests for Exercise 6 ---\n",
        "display(exercise_6_process_car_names())\n",
        "run_tests(TestExercise6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "Scl7WhCiQW6X",
        "outputId": "942fcdfe-d5a1-44d5-b225-3cfb8aff8e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exercise 6 body: Load 'mpg', process car names ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running tests from TestExercise6 ---\n",
            "\n",
            "Setting up TestExercise6: Loading original mpg data and running function...\n",
            "Setup WARNING: Exercise 6 function returned None.\n",
            "test_ex6_brand_extraction_and_cleaning (__main__.TestExercise6.test_ex6_brand_extraction_and_cleaning)\n",
            "Test Ex6 Step 2: Checks specific 'brand' values *after* extraction and replacement. ... \n",
            "Running test_ex6_brand_extraction_and_cleaning...\n",
            "skipped 'Ex6 Skipped (brand cleaning): Result data not available.'\n",
            "test_ex6_cleaned_name_creation (__main__.TestExercise6.test_ex6_cleaned_name_creation)\n",
            "Test Ex6 Step 3: Checks specific 'cleaned_name' values (removal of *original* first word). ... \n",
            "Running test_ex6_cleaned_name_creation...\n",
            "skipped 'Ex6 Skipped (cleaned_name creation): Result data not available.'\n",
            "test_ex6_data_types (__main__.TestExercise6.test_ex6_data_types)\n",
            "Test Ex6: Checks the data types of the new columns. ... \n",
            "Running test_ex6_data_types...\n",
            "skipped 'Ex6 Skipped (dtypes): Result data not available.'\n",
            "test_ex6_initial_brand_extraction (__main__.TestExercise6.test_ex6_initial_brand_extraction)\n",
            "Test Ex6 Step 1: Checks 'brand' column *before* cleaning (contains original first word). ... \n",
            "Running test_ex6_initial_brand_extraction...\n",
            "skipped 'Ex6 Skipped (initial brand): Result data not available.'\n",
            "test_ex6_other_columns_unchanged (__main__.TestExercise6.test_ex6_other_columns_unchanged)\n",
            "Test Ex6: Checks that columns other than 'brand' and 'cleaned_name' are identical to original. ... \n",
            "Running test_ex6_other_columns_unchanged...\n",
            "skipped 'Ex6 Skipped (unchanged cols): Result data not available.'\n",
            "test_ex6_structure_columns (__main__.TestExercise6.test_ex6_structure_columns)\n",
            "Test Ex6: Checks result type, existence and non-emptiness of new columns. ... \n",
            "Running test_ex6_structure_columns...\n",
            "skipped 'Ex6 Skipped (structure): Result data not available (function returned None).'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 6 tests in 0.021s\n",
            "\n",
            "OK (skipped=6)\n",
            "--- Finished tests for TestExercise6 ---\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}